{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b8ca6e",
   "metadata": {},
   "source": [
    "# Flipkart Laptop Reviews ‚Äì Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f782d",
   "metadata": {},
   "source": [
    "This project performs an exploratory analysis of customer reviews for laptops listed on Flipkart. The dataset contains like brand, processor, RAM, storage, operating system, ratings, and more.\n",
    "\n",
    "The goal is to identify patterns and meaningful insights from customer feedback. These insights can help in decision-making related to product development, customer satisfaction, or recommendation systems.\n",
    "\n",
    "The steps in this notebook include:\n",
    "- Setting up the environment\n",
    "- Loading and verifying the dataset\n",
    "- Exploring and cleaning the data\n",
    "- Visualizing important trends\n",
    "- Highlighting key patterns affecting laptop reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4c6bb",
   "metadata": {},
   "source": [
    "### Step 1 ‚Äì Environment Setup and File Encoding\n",
    "\n",
    "This project is built using:\n",
    "- Python (via Anaconda)\n",
    "- Jupyter Notebook (opened in VS Code)\n",
    "- UTF-8 encoding is used when loading the CSV file to avoid problems with special characters like emojis or symbols in text data.\n",
    "\n",
    "UTF-8 is the standard character encoding that supports almost every language and symbol. If the wrong encoding is used, the dataset may show corrupted characters (like ÔøΩ).\n",
    "\n",
    "To verify the encoding:\n",
    "- Open the file using a text editor like Notepad++\n",
    "- Check the \"Encoding\" menu to confirm it's set to UTF-8\n",
    "- If needed, re-save the file with UTF-8 encoding\n",
    "\n",
    "In pandas, UTF-8 is set using `encoding='utf-8'` while reading the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2eb02",
   "metadata": {},
   "source": [
    "#### Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc52ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Set visual theme\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Set display options for better viewing\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39c173",
   "metadata": {},
   "source": [
    "### Step 2 ‚Äì Loading the Dataset\n",
    "\n",
    "The dataset file `laptops_dataset_final_600.csv` is read using pandas with UTF-8 encoding. This ensures proper interpretation of all characters, especially in text-based columns like laptop names or reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading without encoding \n",
    "# df_raw = pd.read_csv('laptops_dataset_final_600.csv')\n",
    "# print(\"Loaded successfully without encoding parameter.\")\n",
    "# display(df_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e877830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended way ‚Äî read with UTF-8 encoding\n",
    "df = pd.read_csv('laptops_dataset_final_600.csv', encoding='utf-8')\n",
    "print(\"Data loaded successfully using UTF-8 encoding.\")\n",
    "\n",
    "# Show the first few records\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1436c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last few records\n",
    "print(\"Last 5 rows: \")\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e0e93",
   "metadata": {},
   "source": [
    "### Step 3 ‚Äì Dataset Overview and Structure\n",
    "\n",
    "The next step involves checking:\n",
    "- Number of rows and columns\n",
    "- Names and data types of all columns\n",
    "- First and last few records\n",
    "- Missing and duplicate data\n",
    "- Unique values in important columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show shape\n",
    "print(f\"Shape of the DataFrame: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all column names\n",
    "print(f\"Column names: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types of each column\n",
    "print(\"Data types: \")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate rows\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['review'].iloc[0])  # Contains emoji or symbols?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b062a64",
   "metadata": {},
   "source": [
    "- Encoding Display Test: The dataset was read using UTF-8 encoding. Special characters and emojis in the review text (such as ü•∫‚ù§Ô∏è) are displayed correctly, confirming that no encoding issues are present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4d670",
   "metadata": {},
   "source": [
    "### Step 4 ‚Äì Understanding Key Columns\n",
    "\n",
    "This dataset contains customer review information for various laptops listed on Flipkart. Below is a quick description of the available columns:\n",
    "\n",
    "- `product_name`: The name and model of the laptop.\n",
    "- `overall_rating`: The average rating given by all users for that product.\n",
    "- `no_ratings`: Total number of users who rated the product.\n",
    "- `no_reviews`: Total number of written reviews.\n",
    "- `rating`: Rating given in this specific review (e.g., 1 to 5 stars).\n",
    "- `title`: Title/summary of the review.\n",
    "- `review`: Full content of the review.\n",
    "\n",
    "These columns focus on customer feedback rather than hardware specifications. As such, analysis will focus on trends in ratings, review counts, and review content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique products\n",
    "print(\"Number of unique laptop models:\", df['product_name'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st five Sample product names\n",
    "print(\"Sample product names:\")\n",
    "print(df['product_name'].unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a232d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of individual review ratings\n",
    "print(\"Rating distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique overall ratings\n",
    "print(\"Unique average (overall) ratings:\")\n",
    "print(df['overall_rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb20efd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st ten Sample review titles\n",
    "print(\"Sample review titles:\")\n",
    "print(df['title'].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0487e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st three Sample review text\n",
    "print(\"Sample full reviews:\")\n",
    "print(df['review'].unique()[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d94c7e",
   "metadata": {},
   "source": [
    "#### Checking for Whitespace\n",
    "\n",
    "This step checks if any text fields have unnecessary leading or trailing spaces. If any are found, they will be removed to clean the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3eb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for leading/trailing whitespace in product_name\n",
    "print(\"product_name: \",df['product_name'].apply(lambda x: x != x.strip()).sum())\n",
    "print(\"title: \",df['title'].apply(lambda x: x != x.strip()).sum())\n",
    "print(\"review: \",df['review'].apply(lambda x: x != x.strip()).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf824c9b",
   "metadata": {},
   "source": [
    "All key text fields (`product_name`, `title`, and `review`) were checked for leading and trailing whitespace. No issues were found, so no cleaning was necessary for this part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391661ad",
   "metadata": {},
   "source": [
    "### Step 5 ‚Äì Data Cleaning\n",
    "\n",
    "To prepare the dataset for accurate analysis, the following actions are performed:\n",
    "- Remove duplicate records\n",
    "- Convert `no_ratings` and `no_reviews` columns to numeric types by removing non-numeric characters like commas and plus signs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7322eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "print(\"Shape of the DataFrame: \", df.shape)\n",
    "\n",
    "#copying the dataframe to a new dataframe\n",
    "df_cp = df.copy()\n",
    "print(\"Shape of the New DataFrame: \",df_cp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c48ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df_cp.drop_duplicates(inplace=True)\n",
    "\n",
    "# Confirm updated shape\n",
    "print(\"Shape after removing duplicates:\", df_cp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a776c",
   "metadata": {},
   "source": [
    "- Removing Duplicate Rows: The original dataset had 24,113 rows. After checking for duplicates, 7,122 duplicate rows were found and removed. The cleaned dataset now contains 16,991 unique records. A separate copy `df_cp` was created for cleaning to keep the original data intact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e31f7",
   "metadata": {},
   "source": [
    "#### Cleaning Count Columns (`no_ratings` and `no_reviews`)\n",
    "\n",
    "The columns `no_ratings` and `no_reviews` originally contain text characters such as commas and plus signs (e.g., \"1,234+\", \"100+\"). These need to be converted into numeric types to support meaningful analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dabaa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the format of the values before cleaning\n",
    "print(\"Sample no_ratings values (before):\", df_cp['no_ratings'].unique()[:5])\n",
    "print(\"Sample no_reviews values (before):\", df_cp['no_reviews'].unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c6138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean count columns\n",
    "def clean_count_column(col):\n",
    "    return col.str.replace(',', '', regex=False).str.replace('+', '', regex=False).astype(int)\n",
    "\n",
    "# Apply cleaning to both columns in df_cp\n",
    "df_cp['no_ratings'] = clean_count_column(df_cp['no_ratings'])\n",
    "df_cp['no_reviews'] = clean_count_column(df_cp['no_reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types and preview cleaned values\n",
    "print(\"Data types after cleaning:\")\n",
    "print(df_cp[['no_ratings', 'no_reviews']].dtypes)\n",
    "\n",
    "print(\"\\nSample cleaned values:\")\n",
    "print(df_cp[['no_ratings', 'no_reviews']].head())\n",
    "\n",
    "print(\"Sample no_ratings values (after):\", df_cp['no_ratings'].unique()[:5])\n",
    "print(\"Sample no_reviews values (after):\", df_cp['no_reviews'].unique()[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
